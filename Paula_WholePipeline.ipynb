{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348c0b0-1dbd-4a98-8c61-7fcbf5f9adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.shell import spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import ArrayType, FloatType, DecimalType, StringType, IntegerType\n",
    "from pyspark.sql.functions import size\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col,when\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.pandas.spark import functions as SF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d14a0-7093-4f91-b97b-420e867d2011",
   "metadata": {},
   "source": [
    "## Connect to duckDB and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375d034-678d-42af-bf16-fd6c9833ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822153e-930e-4bb6-b6e0-657c60a38cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tables structure:\n",
    "\n",
    "for table in ['train', 'test', 'validation']:\n",
    "    # Drop the tables if they already exist\n",
    "    try:\n",
    "        con.execute('''DROP TABLE ''' + table)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Create the table structures (with labels column for the train set):\n",
    "    if table == 'train':\n",
    "        # With label\n",
    "        con.execute('''\n",
    "        CREATE TABLE ''' + table + '''(num INT, tconst VARCHAR, primaryTitle VARCHAR, originalTitle VARCHAR, startYear varchar,\n",
    "        endYear varchar, runtimeMinutes VARCHAR, numVotes FLOAT, label BOOL);\n",
    "        ''')\n",
    "    else:\n",
    "        con.execute('''\n",
    "        CREATE TABLE ''' + table + '''(num INT, tconst VARCHAR, primaryTitle VARCHAR, originalTitle VARCHAR, startYear varchar,\n",
    "        endYear varchar, runtimeMinutes VARCHAR, numVotes FLOAT);\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fe4f8-f806-4b73-9adc-335d483f78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With copy the CSVs are appended to one table\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "path = os.getcwd() + \"/data/\"\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "for f in files:\n",
    "    file = 'data/'+f\n",
    "    if 'train-' in f:\n",
    "        print('Reading train file...', f)\n",
    "        con.execute(\"COPY train FROM '\"+file+\"' (AUTO_DETECT TRUE)\")\n",
    "            \n",
    "    if 'test_' in f:\n",
    "        print('Reading test file...', f)\n",
    "        con.execute(\"COPY test FROM '\"+file+\"' (AUTO_DETECT TRUE)\")\n",
    "    \n",
    "    if 'validation_' in f:\n",
    "        print('Reading validation file...', f)\n",
    "        con.execute(\"COPY validation FROM '\"+file+\"' (AUTO_DETECT TRUE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164f8f4-da14-46ec-9a49-fa12c2379b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(''' SELECT * FROM train''').fetch_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2095001f-7120-4e2d-add5-16bba1a6f15d",
   "metadata": {},
   "source": [
    "Get the JSONs into different tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cb442-a397-486b-8f65-d18a9ad09f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonStr = 'writing.json'\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "try:\n",
    "    df = pd.read_json(jsonStr)\n",
    "except:\n",
    "    df = pd.read_json('data/'+jsonStr)\n",
    "con.execute(\"CREATE TABLE writing AS SELECT * FROM 'df'\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e478125-48a1-492d-828a-c652cc2de019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jsonStr2 = 'directing.json'\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "try:\n",
    "    df2 = pd.read_json(jsonStr2)\n",
    "except:\n",
    "    df2 = pd.read_json('data/'+jsonStr2)\n",
    "\n",
    "con.execute(\"CREATE TABLE directing AS SELECT * FROM 'df2'\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84df25-3334-4b2d-a2f7-a617bc1b4e4b",
   "metadata": {},
   "source": [
    "## From DB to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c19dd-8d6c-459b-935f-e6863810f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"IMDB\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1ade3-8a56-4b8d-98c6-4410c83d0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duckDB tables in spark\n",
    "\n",
    "train_df=spark.createDataFrame(con.execute(\"SELECT * FROM train\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM train\").fetchdf()),\n",
    "                                                                                  None))\n",
    "test_df=spark.createDataFrame(con.execute(\"SELECT * FROM test\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM test\").fetchdf()),\n",
    "                                                                                  None))\n",
    "validation_df=spark.createDataFrame(con.execute(\"SELECT * FROM validation\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM validation\").fetchdf()),\n",
    "                                                                                  None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050ec8d-e9f6-49d9-bff7-b8002a45aaed",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a69db-06b9-4b53-9529-9431a2e90828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values from the desired columns\n",
    "def drop_nulls(df, cols):\n",
    "    df = df.dropna(subset=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af87a2-0502-4b86-ae02-bed25b34c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap start and endyear where necesseary and add YearSinceRealease feature\n",
    "from pyspark.sql.functions import when\n",
    "def set_years(df):\n",
    "    df = df.withColumn(\"endyear\", when(df.endyear == \"\\\\N\",\"2022\")\n",
    "                                 .otherwise(df.endyear))\n",
    "    df = df.withColumn(\"startyear\", when(df.startyear == \"\\\\N\", df.endyear)\n",
    "                              .otherwise(df.startyear))\n",
    "    df = df.withColumn(\"endyear\", when(df.endyear == df.startyear, \"2022\")\n",
    "                              .otherwise(df.endyear))\n",
    "    df = df.withColumn('YearSinceRealease', ( df['endyear'] - df['startyear'] ))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee4c34-8efe-479f-8b32-cc9faeb3f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check runtime minutes to the mean when not available\n",
    "def runtime_nulls(df):\n",
    "    df = df.where(df.runtimeminutes != '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4762d536-6872-45ee-9cfc-ff9f7bb297f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with mean in empty rows:\n",
    "from pyspark.sql.functions import avg\n",
    "def fill_with_mean(df, cols): \n",
    "    # First convert the non numeric values to None:\n",
    "    for col in cols:\n",
    "        df = df.withColumn(col, when(df[col] == \"\\\\N\", None)\n",
    "                                 .otherwise(df[col]))\n",
    "    # Then fill with the mean:\n",
    "    fill_values = {column: df.agg({column:\"mean\"}).first()[0] for column in cols}\n",
    "    df = df.na.fill(fill_values)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723df05c-50b1-4c52-a050-2126b8a6fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE THE PREPROCESSING:\n",
    "\n",
    "def preprocessing(df):\n",
    "    # Drop rows that have null values in runtimeminutes/numvotes\n",
    "    # df = drop_nulls(df, [\"runtimeminutes\",\"numvotes\"])\n",
    "    # Swap start and endyear where necesseary, set end year and add YearSinceRealease feature\n",
    "    df = set_years(df)\n",
    "    # Check Runtime minutes\n",
    "    df = fill_with_mean(df, [\"runtimeminutes\"])\n",
    "    return df\n",
    "    \n",
    "train_proc = preprocessing(train_df)\n",
    "test_proc = preprocessing(test_df)\n",
    "val_proc = preprocessing(validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd3798-fe0d-4995-8093-87cd3a42f52d",
   "metadata": {},
   "source": [
    "## Additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f08ad9-0f76-47c4-a3f8-24e646fa292e",
   "metadata": {},
   "source": [
    "#### Save in DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c617181-7e90-42d4-8441-dda7cfe836c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    con.execute(\"CREATE TABLE additional_train AS SELECT * FROM 'movies_info_train.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_test AS SELECT * FROM 'movies_info_test.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_val AS SELECT * FROM 'movies_info_val.csv';\")\n",
    "except:\n",
    "    con.execute(\"CREATE TABLE additional_train AS SELECT * FROM 'data/movies_info_train.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_test AS SELECT * FROM 'data/movies_info_test.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_val AS SELECT * FROM 'data/movies_info_val.csv';\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079bed5-bdff-41ae-b767-c0d223ee9278",
   "metadata": {},
   "source": [
    "#### From DB to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8ba85-8ca5-42dc-9ab5-2d209afd221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duckDB tables in spark\n",
    "\n",
    "train_extra_df=spark.createDataFrame(con.execute(\"SELECT * FROM additional_train\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM additional_train\").fetchdf()),\n",
    "                                                                                  None))\n",
    "test_extra_df=spark.createDataFrame(con.execute(\"SELECT * FROM additional_test\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM additional_test\").fetchdf()),\n",
    "                                                                                  None))\n",
    "validation_extra_df=spark.createDataFrame(con.execute(\"SELECT * FROM additional_val\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM additional_val\").fetchdf()),\n",
    "                                                                                  None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63903bdd-fef7-4d2c-82bd-fbd740d70672",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train dataset size:',train_df.count())\n",
    "print('Extra features size:',train_extra_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90441d32-54e3-4b46-bf85-53ec595c84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_df=spark.createDataFrame(con.execute(\"SELECT * FROM writing\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM writing\").fetchdf()),\n",
    "                                                                                  None))\n",
    "directors_df=spark.createDataFrame(con.execute(\"SELECT * FROM directing\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM directing\").fetchdf()),\n",
    "                                                                                  None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bfe23d-e2e4-4825-9787-1c92352a7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "grouped_writers = writers_df.groupby('movie').agg(collect_list('writer').alias(\"writers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97b286-854c-4639-a60a-bbb6386133de",
   "metadata": {},
   "source": [
    "#### Merge all dataframe togerther (inito_numpy writers, directors, extra data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede0372-81c8-4b5b-a79d-ac1517a3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "def merge_dfs(df, df_extra):\n",
    "    horiztnlcombined_data = df.join(df_extra, df.tconst == df_extra.imdb_id, 'inner')\n",
    "    print(df.count(), ' + ', df_extra.count(), ' --> ', horiztnlcombined_data.count())\n",
    "    return horiztnlcombined_data\n",
    "\n",
    "train_merge_df = merge_dfs(train_df, train_extra_df)\n",
    "test_merge_df = merge_dfs(test_df, test_extra_df)\n",
    "val_merge_df = merge_dfs(validation_df, validation_extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9aced-8f05-4819-8432-b161d7669a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_df = directors_df.selectExpr(\"movie as movie_d\",\"director as director\")\n",
    "writers_directors = grouped_writers.join(directors_df, grouped_writers.movie == directors_df.movie_d, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905af21-5d49-4148-bb4f-47057fcddd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def final_merge(df, df_writ_dir):\n",
    "    final_df = df.join(df_writ_dir, df.tconst == df_writ_dir.movie, 'inner')\n",
    "    return final_df\n",
    "\n",
    "train_final_df = final_merge(train_merge_df, writers_directors)\n",
    "test_final_df = final_merge(test_merge_df, writers_directors)\n",
    "val_final_df = final_merge(val_merge_df, writers_directors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ef08c-096e-4873-8a0b-0583ba49ed51",
   "metadata": {},
   "source": [
    "## Prepare for ML algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb8305-f358-434d-a144-bc5bc075d0ba",
   "metadata": {},
   "source": [
    "#### Keep only useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f0517-c826-454a-a144-6794ce4de00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df, cols):\n",
    "    drop_df = df.drop(*cols)\n",
    "    return drop_df\n",
    "\n",
    "cols2drop = ('num', 'tconst', 'primarytitle', 'originaltitle', 'endyear', 'imdb_id', 'belongs_to_collection', \n",
    "        'budget', 'id', 'original_title', 'overview', 'production_companies',\n",
    "         'release_date', 'revenue', 'runtime', 'tagline', 'title', 'video', 'vote_count', 'spoken_language_list',  'movie', 'movie_d')\n",
    "\n",
    "train_df_clean = drop_cols(train_final_df, cols2drop)\n",
    "test_df_clean = drop_cols(test_final_df, cols2drop)\n",
    "val_df_clean = drop_cols(val_final_df, cols2drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a2317-bb94-42b4-8335-438d9e34bb9e",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbbfa0-2957-4ff8-ac98-ad907fc02f40",
   "metadata": {},
   "source": [
    "Trying to encode with One Hot Encoder for spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547b000-84b7-4231-83e2-a5d25120532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ##  import the required libraries\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "\n",
    "def hot_encode(df, col):\n",
    "    ##  numeric indexing for the strings (indexing starts from 0)\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=col+'_ind')\n",
    "    df = indexer.fit(df).transform(df)\n",
    "    ohe = OneHotEncoder(inputCol=col+'_ind', outputCol=col+'OHEVector')\n",
    "    df = ohe.fit(df).transform(df)\n",
    "    return df\n",
    "\n",
    "    \n",
    "train_df_encode = hot_encode(train_df_clean, 'genre_list')\n",
    "test_df_encode = hot_encode(test_df_clean, 'genre_list')\n",
    "val_df_encode = hot_encode(val_df_clean, 'genre_list')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6147e5-fdff-4fbc-af35-5a220440a773",
   "metadata": {},
   "source": [
    "#### Convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d72777-8719-40b8-a681-d9d3090eca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pandas = test_df_encode.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db50c7e-4b57-47f8-bf2e-dbc8df8f24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e2094-2097-4f33-b925-4df3c44b2811",
   "metadata": {},
   "source": [
    "#### ML Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0c5a4-104e-464c-8e6e-7a0b2ce4980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pandas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598876ac-90d5-44ee-8947-14c90dfeb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d3235-8577-4bb5-88d0-5ca798cc3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46581451-326f-4463-a92d-c6b60445cbc3",
   "metadata": {},
   "source": [
    "##### Create df to feed to the model (should be done in PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff700c6-5591-45e9-8f55-6a91dd5e5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = train_df.toPandas()\n",
    "writers_pd = writers_df.toPandas()\n",
    "directors_pd = directors_df.toPandas()\n",
    "more_pd = moredata_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49b510-df70-477a-afea-d25ec2509a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = test_hidden_df.toPandas()\n",
    "val_pd = validation_hidden_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8171729-2f31-43ea-a7b4-c48a9dd95162",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1 = train_pd.merge(more_pd, left_on = 'tconst', right_on = 'imdb_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1defc47b-60a7-4e76-b2a6-e32d4a96a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eefaaec-acc8-4833-97fa-d46d9c4273c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test = test_pd.merge(more_pd, left_on = 'tconst', right_on = 'imdb_id', how = 'inner')\n",
    "merged_val = val_pd.merge(more_pd, left_on = 'tconst', right_on = 'imdb_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f630c-2d44-48b3-bc57-f9b2aeade0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6793473-d052-4909-ae7f-a26a7ef9305b",
   "metadata": {},
   "source": [
    "##### One hot encoding for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ced80-1468-4347-9350-71ab2a09a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_g = pd.DataFrame()\n",
    "one_hot_g['genres'] = final_pandas['genre_list'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'').str.split(',')\n",
    "#one_hot_g['genres'] = final_pandas['genre_list'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd92c6-9671-4d77-9498-0d2bc66a82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_pr = pd.DataFrame()\n",
    "one_hot_g['prods'] = final_pandas['production_list'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'').str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51ad3b-c397-4ebc-afa2-03d469422b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_g['genres'] = one_hot_g['genres'].apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7cdf97-c11e-4dc2-b059-ea0560a374ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_w = pd.DataFrame()\n",
    "one_hot_w['writers'] = final_pandas['writers'].apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c69ca1-ff89-40f7-a460-2a32bbaab25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot_df = pd.DataFrame(mlb.fit_transform(one_hot_g['genres']),columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd9b28-ac67-4277-b190-52c7b7f8b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df1 = pd.DataFrame(mlb.fit_transform(one_hot_w['writers']),columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b980dc0-392b-4dd9-b31b-d2b538e27c2e",
   "metadata": {},
   "source": [
    "TODO: Include the directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb09ef5-b496-44d4-80c7-635220dd6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_d = pd.DataFrame()\n",
    "# Get one hot encoding of columns B\n",
    "one_hot_d = pd.get_dummies(final_pandas['director'])\n",
    "# Drop column B as it is now encoded\n",
    "#df = df.drop('B',axis = 1)\n",
    "# Join the encoded df\n",
    "#final_pandas = final_pandas.join(one_hot_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1d210-a80b-4bd7-8d96-5585e2cb9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pandas = final_pandas.join(one_hot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8dbcf8-ac83-4cba-8163-cdf515bb7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pandas = final_pandas.join(one_hot_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779ff8e-26fc-4a67-b262-ef3348b7fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(final_pandas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569e84e-dda5-4d4e-b066-24cda7500517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "# labelencoder = LabelEncoder()\n",
    "# # Assigning numerical values and storing in another column\n",
    "# merged1['startyear_Cat'] = labelencoder.fit_transform(merged1['startyear'])\n",
    "# merged1['production_countr_list_Cat'] = labelencoder.fit_transform(merged1['production_countr_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ed062-4ec1-4877-b979-0628bc73862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# To define the input and output feature\n",
    "# 'num','tconst','primarytitle','originaltitle', 'endyear',\n",
    "# x = merged1.drop([\"num\",\"tconst\",\"primarytitle\",\"originaltitle\", \"endyear\",\"imdb_id\", \"belongs_to_collection\", \"budget\",\n",
    "#         \"id\", \"original_title\", \"overview\", \"tagline\", \"title\", \"video\", \"production_companies\", \"release_date\",\n",
    "#         \"revenue\", \"runtime\",'startyear',\"adult\", \"original_language\", \"genre_list\", \"production_list\", \"production_countr_list\",\n",
    "#                        \"spoken_language_list\",\"genres_bin\",\"production_bin\", \"label\"],axis=1)\n",
    "\n",
    "x = final_pandas.drop([\"genre_list\", \"production_list\",\"original_language\",\n",
    "                       'production_countr_list', 'writers', 'director','','\\\\N', \"label\"], axis=1)\n",
    "\n",
    "x['runtimeminutes'] = x['runtimeminutes'].astype(float)\n",
    "x['startyear'] = x['startyear'].astype(float)\n",
    "x['adult'] = x['adult'].astype(int)\n",
    "y = final_pandas['label']\n",
    "# train and test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a81bf-ad43-4e1f-9521-6c42bb0e0f29",
   "metadata": {},
   "source": [
    "##### Make predictions for hidden data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361475d9-2dfe-4997-a7e3-a8b9529b8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged_test.drop([\"num\",\"tconst\",\"primarytitle\",\"originaltitle\", \"endyear\",\"imdb_id\", \"belongs_to_collection\", \"budget\",\n",
    "        \"id\", \"original_title\", \"overview\", \"tagline\", \"title\", \"video\", \"production_companies\", \"release_date\",\n",
    "        \"revenue\", \"runtime\",'startyear',\"adult\", \"original_language\", \"genre_list\", \"production_list\", \"production_countr_list\",\n",
    "                       \"spoken_language_list\",\"genres_bin\",\"production_bin\", \"label\"],axis=1)\n",
    "x['runtimeminutes'] = x['runtimeminutes'].astype(float)\n",
    "#prediction on the test set\n",
    "y_pred=clf.predict(x)\n",
    "#rounding the values\n",
    "y_pred=y_pred.round(0)\n",
    "#converting from float to integer\n",
    "y_pred=y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9051fab-2523-43b7-b74f-f53df2dba146",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "\n",
    "    'boosting_type':'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'n_estimators':10000,\n",
    "    'learning_rate':0.3,\n",
    "    'num_leaves':2840,\n",
    "    'max_depth':10,\n",
    "    'min_data_in_leaf': 300,\n",
    "'lambda_l1': 35,\n",
    "'lambda_l2': 65,\n",
    "'min_gain_to_split': 7.394615335964813,\n",
    "'bagging_fraction': 0.6,\n",
    "'bagging_freq': 1,\n",
    "'feature_fraction': 0.3\n",
    "                } \n",
    "d_train=lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "#train the model \n",
    "clf=lgb.train(lgb_params,d_train) #train the model on 100 epocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b35db-80f3-46f6-80b5-4e38e6859268",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('model_lgbm.txt')\n",
    "clf.save_model(\"model_lgbm.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0848af-a1b3-4842-a126-c7f8f1df87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lgb = lgb.Booster(model_file='model_lgbm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa951be6-11ae-4f20-a2a8-75a85226cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on the test set\n",
    "y_pred=clf.predict(x_test)\n",
    "#rounding the values\n",
    "y_pred=y_pred.round(0)\n",
    "#converting from float to integer\n",
    "y_pred=y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e8a5f-f73c-4bd4-96d2-42cef80f8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score, accuracy_score\n",
    "#roc_auc_score metric\n",
    "accuracy_score(y_pred,y_test.values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dde8a-d385-420c-ad7d-b7eb5df4b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pd = pd.read_csv('validation_hidden.csv')\n",
    "test_pd = pd.read_csv('test_hidden.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefef5a-0543-4979-aa9c-67fbf84aa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619d408-3782-4a96-b810-206fd06831a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543f08-6bd0-4dd0-afdd-231231ebd00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b8a26-c4a8-48db-b724-42dcd845c6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e930ce-3b9e-490d-ab17-32c4436d2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "final_pandas['startyear_Cat'] = labelencoder.fit_transform(final_pandas['startyear'])\n",
    "# final_pandas['writers_Cat'] = labelencoder.fit_transform(final_pandas['writer'])\n",
    "# final_pandas['directors_Cat'] = labelencoder.fit_transform(final_pandas['director'])\n",
    "final_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882f3e2-1daf-4c60-adc6-221fe3db4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define the input and output feature\n",
    "# 'num','tconst','primarytitle','originaltitle', 'endyear',\n",
    "x = final_pandas.drop(['startyear',\"adult\", \"original_language\", \n",
    "                       \"popularity\",\"vote_average\", \"vote_count\", \"genre_list\", \"production_list\", \"production_countr_list\",\n",
    "                       \"spoken_language_list\", 'writer','director'],axis=1)\n",
    "x = x.dropna()\n",
    "x['runtimeminutes'] = x['runtimeminutes'].astype(float)\n",
    "y = x['label']\n",
    "x = x.drop(['label'],axis=1)\n",
    "# train and test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8da00c-357b-43a8-82e5-579f0e20cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31501b-b69f-4037-a2f0-fb1d727b52a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd392bd-001c-4f88-9929-4142a3559f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11df7f9-47c1-4e99-9224-6ff7843f2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy {:.4f}'.format(clf.score(x_train,y_train)))\n",
    "print('Testing accuracy {:.4f}'.format(clf.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cba51-b136-411e-9517-822ce440e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7133f68-32c0-4b82-97e6-6ed798ebf404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
