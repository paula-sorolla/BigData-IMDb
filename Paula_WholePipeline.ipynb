{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a348c0b0-1dbd-4a98-8c61-7fcbf5f9adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/24 08:56:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.2.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.9.7 (default, Oct 10 2021 15:08:54)\n",
      "Spark context Web UI available at http://1eee0feb924b:4040\n",
      "Spark context available as 'sc' (master = local[*], app id = local-1648112183181).\n",
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.shell import spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import ArrayType, FloatType, DecimalType, StringType, IntegerType\n",
    "from pyspark.sql.functions import size\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col,when\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.pandas.spark import functions as SF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d14a0-7093-4f91-b97b-420e867d2011",
   "metadata": {},
   "source": [
    "## Connect to duckDB and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9375d034-678d-42af-bf16-fd6c9833ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=':memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8822153e-930e-4bb6-b6e0-657c60a38cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tables structure:\n",
    "\n",
    "for table in ['train', 'test', 'validation']:\n",
    "    # Drop the tables if they already exist\n",
    "    try:\n",
    "        con.execute('''DROP TABLE ''' + table)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Create the table structures (with labels column for the train set):\n",
    "    if table == 'train':\n",
    "        # With label\n",
    "        con.execute('''\n",
    "        CREATE TABLE ''' + table + '''(num INT, tconst VARCHAR, primaryTitle VARCHAR, originalTitle VARCHAR, startYear varchar,\n",
    "        endYear varchar, runtimeMinutes VARCHAR, numVotes FLOAT, label BOOL);\n",
    "        ''')\n",
    "    else:\n",
    "        con.execute('''\n",
    "        CREATE TABLE ''' + table + '''(num INT, tconst VARCHAR, primaryTitle VARCHAR, originalTitle VARCHAR, startYear varchar,\n",
    "        endYear varchar, runtimeMinutes VARCHAR, numVotes FLOAT);\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0fe4f8-f806-4b73-9adc-335d483f78f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test file... test_hidden.csv\n",
      "Reading train file... train-1.csv\n",
      "Reading train file... train-2.csv\n",
      "Reading train file... train-3.csv\n",
      "Reading train file... train-4.csv\n",
      "Reading train file... train-5.csv\n",
      "Reading train file... train-6.csv\n",
      "Reading train file... train-7.csv\n",
      "Reading train file... train-8.csv\n",
      "Reading validation file... validation_hidden.csv\n"
     ]
    }
   ],
   "source": [
    "#With copy the CSVs are appended to one table\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "path = os.getcwd() + \"/data/\"\n",
    "files = [f for f in os.listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "for f in files:\n",
    "    file = 'data/'+f\n",
    "    if 'train-' in f:\n",
    "        print('Reading train file...', f)\n",
    "        con.execute(\"COPY train FROM '\"+file+\"' (AUTO_DETECT TRUE)\")\n",
    "            \n",
    "    if 'test_' in f:\n",
    "        print('Reading test file...', f)\n",
    "        con.execute(\"COPY test FROM '\"+file+\"' (AUTO_DETECT TRUE)\")\n",
    "    \n",
    "    if 'validation_' in f:\n",
    "        print('Reading validation file...', f)\n",
    "        con.execute(\"COPY validation FROM '\"+file+\"' (AUTO_DETECT TRUE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c164f8f4-da14-46ec-9a49-fa12c2379b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7959 1086 955\n"
     ]
    }
   ],
   "source": [
    "train_size = con.execute(''' SELECT * FROM train''').fetch_df().shape[0]\n",
    "test_size = con.execute(''' SELECT * FROM test''').fetch_df().shape[0]\n",
    "val_size = con.execute(''' SELECT * FROM validation''').fetch_df().shape[0]\n",
    "print(train_size, test_size, val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2095001f-7120-4e2d-add5-16bba1a6f15d",
   "metadata": {},
   "source": [
    "Get the JSONs into different tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9cb442-a397-486b-8f65-d18a9ad09f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonStr = 'writing.json'\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "try:\n",
    "    df = pd.read_json(jsonStr)\n",
    "except:\n",
    "    df = pd.read_json('data/'+jsonStr)\n",
    "con.execute(\"CREATE TABLE writing AS SELECT * FROM 'df'\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e478125-48a1-492d-828a-c652cc2de019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jsonStr2 = 'directing.json'\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "# Convert JSON to DataFrame Using read_json()\n",
    "try:\n",
    "    df2 = pd.read_json(jsonStr2)\n",
    "except:\n",
    "    df2 = pd.read_json('data/'+jsonStr2)\n",
    "\n",
    "con.execute(\"CREATE TABLE directing AS SELECT * FROM 'df2'\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84df25-3334-4b2d-a2f7-a617bc1b4e4b",
   "metadata": {},
   "source": [
    "## From DB to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449c19dd-8d6c-459b-935f-e6863810f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"IMDB\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c1ade3-8a56-4b8d-98c6-4410c83d0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duckDB tables in spark\n",
    "\n",
    "train_df=spark.createDataFrame(con.execute(\"SELECT * FROM train\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM train\").fetchdf()),\n",
    "                                                                                  None))\n",
    "test_df=spark.createDataFrame(con.execute(\"SELECT * FROM test\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM test\").fetchdf()),\n",
    "                                                                                  None))\n",
    "validation_df=spark.createDataFrame(con.execute(\"SELECT * FROM validation\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM validation\").fetchdf()),\n",
    "                                                                                  None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aadb65e-0259-4a6a-b719-5d2c0a21da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert test_df.count() == test_size, 'Incorrect test size'\n",
    "# assert validation_df.count() == val_size, 'Incorrect validation size'\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050ec8d-e9f6-49d9-bff7-b8002a45aaed",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424a69db-06b9-4b53-9529-9431a2e90828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values from the desired columns\n",
    "def drop_nulls(df, cols):\n",
    "    df = df.dropna(subset=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42af87a2-0502-4b86-ae02-bed25b34c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap start and endyear where necesseary and add YearSinceRealease feature\n",
    "from pyspark.sql.functions import when\n",
    "def set_years(df):\n",
    "    df = df.withColumn(\"endyear\", when(df.endyear == \"\\\\N\",\"2022\")\n",
    "                                 .otherwise(df.endyear))\n",
    "    df = df.withColumn(\"startyear\", when(df.startyear == \"\\\\N\", df.endyear)\n",
    "                              .otherwise(df.startyear))\n",
    "    df = df.withColumn(\"endyear\", when(df.endyear == df.startyear, \"2022\")\n",
    "                              .otherwise(df.endyear))\n",
    "    df = df.withColumn('YearSinceRealease', ( df['endyear'] - df['startyear'] ))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67ee4c34-8efe-479f-8b32-cc9faeb3f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check runtime minutes to the mean when not available\n",
    "def runtime_nulls(df):\n",
    "    df = df.where(df.runtimeminutes != '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4762d536-6872-45ee-9cfc-ff9f7bb297f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with mean in empty rows:\n",
    "from pyspark.sql.functions import avg\n",
    "def fill_with_mean(df, cols): \n",
    "    # First convert the non numeric values to None:\n",
    "    for col in cols:\n",
    "        df = df.withColumn(col, when(df[col] == \"\\\\N\", None)\n",
    "                                 .otherwise(df[col]))\n",
    "    # Then fill with the mean:\n",
    "    fill_values = {column: df.agg({column:\"mean\"}).first()[0] for column in cols}\n",
    "    df = df.na.fill(fill_values)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723df05c-50b1-4c52-a050-2126b8a6fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# EXECUTE THE PREPROCESSING:\n",
    "\n",
    "def preprocessing(df):\n",
    "    # Drop rows that have null values in runtimeminutes/numvotes\n",
    "    # df = drop_nulls(df, [\"runtimeminutes\",\"numvotes\"])\n",
    "    # Swap start and endyear where necesseary, set end year and add YearSinceRealease feature\n",
    "    df = set_years(df)\n",
    "    # Check Runtime minutes\n",
    "    df = fill_with_mean(df, [\"runtimeminutes\"])\n",
    "    return df\n",
    "    \n",
    "train_proc = preprocessing(train_df)\n",
    "test_proc = preprocessing(test_df)\n",
    "val_proc = preprocessing(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424ac3e9-1b76-4c3a-8a30-71ca5de00f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert test_proc.count() == test_size, 'Incorrect test size'\n",
    "# assert val_proc.count() == val_size, 'Incorrect validation size'\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd3798-fe0d-4995-8093-87cd3a42f52d",
   "metadata": {},
   "source": [
    "## Additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f08ad9-0f76-47c4-a3f8-24e646fa292e",
   "metadata": {},
   "source": [
    "#### Save in DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c617181-7e90-42d4-8441-dda7cfe836c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    con.execute(\"CREATE TABLE additional_train AS SELECT * FROM 'movies_info_train.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_test AS SELECT * FROM 'movies_info_test.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_val AS SELECT * FROM 'movies_info_val.csv';\")\n",
    "except:\n",
    "    con.execute(\"CREATE TABLE additional_train AS SELECT * FROM 'data/movies_info_train.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_test AS SELECT * FROM 'data/movies_info_test.csv';\")\n",
    "    con.execute(\"CREATE TABLE additional_val AS SELECT * FROM 'data/movies_info_val.csv';\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079bed5-bdff-41ae-b767-c0d223ee9278",
   "metadata": {},
   "source": [
    "#### From DB to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32e8ba85-8ca5-42dc-9ab5-2d209afd221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the duckDB tables in spark\n",
    "\n",
    "train_extra_df=spark.createDataFrame(con.execute(\"SELECT * FROM additional_train\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM additional_train\").fetchdf()),\n",
    "                                                                                  None))\n",
    "test_extra_df=spark.createDataFrame(con.execute(\"SELECT * FROM additional_test\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM additional_test\").fetchdf()),\n",
    "                                                                                  None))\n",
    "validation_extra_df=spark.createDataFrame(con.execute(\"SELECT * FROM additional_val\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM additional_val\").fetchdf()),\n",
    "                                                                                  None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90441d32-54e3-4b46-bf85-53ec595c84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "writers_df=spark.createDataFrame(con.execute(\"SELECT * FROM writing\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM writing\").fetchdf()),\n",
    "                                                                                  None))\n",
    "directors_df=spark.createDataFrame(con.execute(\"SELECT * FROM directing\").fetchdf().where(pd.notnull(con.execute(\"SELECT * FROM directing\").fetchdf()),\n",
    "                                                                                  None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4bfe23d-e2e4-4825-9787-1c92352a7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "grouped_writers = writers_df.groupby('movie').agg(collect_list('writer').alias(\"writers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97b286-854c-4639-a60a-bbb6386133de",
   "metadata": {},
   "source": [
    "#### Merge all dataframe togerther (inito_numpy writers, directors, extra data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dede0372-81c8-4b5b-a79d-ac1517a3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "def merge_dfs(df, df_extra):\n",
    "    horiztnlcombined_data = df.join(df_extra, df.tconst == df_extra.imdb_id, 'inner')\n",
    "    # print(df.count(), ' + ', df_extra.count(), ' --> ', horiztnlcombined_data.count())\n",
    "    return horiztnlcombined_data\n",
    "\n",
    "train_merge_df = merge_dfs(train_df, train_extra_df)\n",
    "test_merge_df = merge_dfs(test_df, test_extra_df)\n",
    "val_merge_df = merge_dfs(validation_df, validation_extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6710e477-483b-4e0a-86ad-a25ab5268362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert test_merge_df.count() == test_size, 'Incorrect test size'\n",
    "# assert val_merge_df.count() == val_size, 'Incorrect validation size'\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4c9aced-8f05-4819-8432-b161d7669a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_df = directors_df.selectExpr(\"movie as movie_d\", \"director as director\")\n",
    "writers_directors = grouped_writers.join(directors_df, grouped_writers.movie == directors_df.movie_d, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3905af21-5d49-4148-bb4f-47057fcddd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def final_merge(df, df_writ_dir):\n",
    "    final_df = df.join(df_writ_dir, df.tconst == df_writ_dir.movie, 'leftouter')\n",
    "    final_df = final_df.dropna(subset=['tconst'])\n",
    "    \n",
    "    return final_df.dropDuplicates(['tconst'])\n",
    "\n",
    "train_final_df = final_merge(train_merge_df, writers_directors)\n",
    "test_final_df = final_merge(test_merge_df, writers_directors)\n",
    "val_final_df = final_merge(val_merge_df, writers_directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2318130f-2720-4a46-a569-148d9ffbde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert test_final_df.count() == test_size, 'Incorrect test size'\n",
    "# assert val_final_df.count() == val_size, 'Incorrect validation size'\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ef08c-096e-4873-8a0b-0583ba49ed51",
   "metadata": {},
   "source": [
    "## Prepare for ML algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb8305-f358-434d-a144-bc5bc075d0ba",
   "metadata": {},
   "source": [
    "#### Keep only useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "947f0517-c826-454a-a144-6794ce4de00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(df, cols):\n",
    "    drop_df = df.drop(*cols)\n",
    "    return drop_df\n",
    "\n",
    "cols2drop = ('num', 'tconst', 'primarytitle', 'originaltitle', 'endyear', 'imdb_id', 'belongs_to_collection', \n",
    "        'budget', 'id', 'original_title', 'overview', 'production_companies',\n",
    "         'release_date', 'revenue', 'runtime', 'tagline', 'title', 'video', 'vote_count', 'spoken_language_list',  'movie', 'movie_d')\n",
    "\n",
    "train_df_clean = drop_cols(train_final_df, cols2drop)\n",
    "test_df_clean = drop_cols(test_final_df, cols2drop)\n",
    "val_df_clean = drop_cols(val_final_df, cols2drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a2317-bb94-42b4-8335-438d9e34bb9e",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbbfa0-2957-4ff8-ac98-ad907fc02f40",
   "metadata": {},
   "source": [
    "Trying to encode with One Hot Encoder for spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6547b000-84b7-4231-83e2-a5d25120532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #   ##  import the required libraries\n",
    "# from pyspark.ml.feature import StringIndexer\n",
    "# from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "\n",
    "# def hot_encode(df, col):\n",
    "#     ##  numeric indexing for the strings (indexing starts from 0)\n",
    "#     indexer = StringIndexer(inputCol=col, outputCol=col+'_ind')\n",
    "#     df = indexer.fit(df).transform(df)\n",
    "#     ohe = OneHotEncoder(inputCol=col+'_ind', outputCol=col+'OHEVector')\n",
    "#     df = ohe.fit(df).transform(df)\n",
    "#     return df\n",
    "\n",
    "    \n",
    "# train_df_encode = hot_encode(train_df_clean, 'genre_list')\n",
    "# test_df_encode = hot_encode(test_df_clean, 'genre_list')\n",
    "# val_df_encode = hot_encode(val_df_clean, 'genre_list')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6147e5-fdff-4fbc-af35-5a220440a773",
   "metadata": {},
   "source": [
    "#### Convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d72777-8719-40b8-a681-d9d3090eca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/24 08:59:30 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df_pandas = train_final_df.toPandas()\n",
    "test_df_pandas = test_final_df.toPandas()\n",
    "val_df_pandas = val_final_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f2007a5-0669-4360-ac25-cfa7a759bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "assert test_df_pandas.shape[0] == test_size, 'Incorrect test size'\n",
    "assert val_df_pandas.shape[0] == val_size, 'Incorrect validation size'\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6793473-d052-4909-ae7f-a26a7ef9305b",
   "metadata": {},
   "source": [
    "#### One hot encoding for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73ea7045-c48d-4989-96bb-1762f53e438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "    \n",
    "def convert_2set(val):\n",
    "    try:\n",
    "        ret = set(val)\n",
    "    except:\n",
    "        ret = set({})\n",
    "    return ret\n",
    "    \n",
    "def hot_encode(df, col):\n",
    "    one_hot = pd.DataFrame()\n",
    "    try:\n",
    "        one_hot[col+'_OH'] = df[col].str.strip('[]').str.replace(' ','').str.replace(\"'\",'').str.split(',')\n",
    "    except: \n",
    "        one_hot[col+'_OH'] = df[col]\n",
    "    one_hot[col+'_OH'] = one_hot[col+'_OH'].apply(lambda x: convert_2set(x))\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    one_hot_df = pd.DataFrame(mlb.fit_transform(one_hot[col+'_OH']),columns=mlb.classes_)\n",
    "    \n",
    "    # Check that we only keep writers that appear at least 5 times in the dataset\n",
    "    cols = list(one_hot_df.columns.values)\n",
    "    for col in cols:\n",
    "        if one_hot_df[col].sum() < 5:\n",
    "            one_hot_df.drop(col, axis=1)\n",
    "    \n",
    "    joined_df = df.join(one_hot_df)\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9cd362a-aa69-4dbe-bb08-6bf95b986142",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_df = hot_encode(train_df_pandas, 'genre_list')\n",
    "# train_encoded_df = hot_encode(train_encoded_df, 'writers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7776603b-5269-46ac-ad9d-0265a11ee74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_df = hot_encode(test_df_pandas, 'genre_list')\n",
    "val_encoded_df = hot_encode(val_df_pandas, 'genre_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b259525a-2c4c-47fa-bc66-227d42931d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "assert train_encoded_df.shape[1] == test_encoded_df.shape[1], \"Test features don't match\"\n",
    "assert train_encoded_df.shape[1] == val_encoded_df.shape[1], \"Validation features don't match\"\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b980dc0-392b-4dd9-b31b-d2b538e27c2e",
   "metadata": {},
   "source": [
    "TODO: Include the directors & writers !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17679b1-e066-4009-83ac-8a3b0990a693",
   "metadata": {},
   "source": [
    "## Train ML Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598876ac-90d5-44ee-8947-14c90dfeb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "319d3235-8577-4bb5-88d0-5ca798cc3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e32ed062-4ec1-4877-b979-0628bc73862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns:\n",
    "cols2drop = ['num', 'tconst', 'primarytitle', 'originaltitle', 'imdb_id',\n",
    "       'belongs_to_collection', 'budget', 'id', 'original_language',\n",
    "       'original_title', 'overview', 'popularity', 'production_companies',\n",
    "       'release_date', 'revenue', 'tagline', 'title', 'video', 'endyear',\n",
    "        'genre_list', 'production_list', 'movie_d', 'director', '',\n",
    "       'production_countr_list', 'spoken_language_list', 'movie', 'writers']\n",
    "\n",
    "# cols2drop\n",
    "x = train_encoded_df.drop(columns=cols2drop)\n",
    "x = x.drop(columns=['label'])\n",
    "x_test_hid = test_encoded_df.drop(columns=cols2drop)\n",
    "x_val_hid = val_encoded_df.drop(columns=cols2drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d320ad10-67d4-4dd3-8680-7133b028e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_float(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0, downcast='infer')\n",
    "    return df\n",
    "\n",
    "x = convert_float(x, ['runtimeminutes', 'adult', 'startyear'])\n",
    "y = train_encoded_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4dea182-7ab8-4fbb-8214-e50429e44778",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hidden_test = convert_float(x_test_hid, ['runtimeminutes', 'adult', 'startyear'])\n",
    "x_hidden_val = convert_float(x_val_hid, ['runtimeminutes', 'adult', 'startyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c417fc14-ad7f-41bc-8bf6-e5cfef33dc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0b37e-8194-4e00-ad60-ac81b4358074",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15689b8a-760f-4db6-af6b-5ce1e4ddcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type':'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'n_estimators':10000,\n",
    "    'learning_rate':0.3,\n",
    "    'num_leaves':2840,\n",
    "    'max_depth':10,\n",
    "    'min_data_in_leaf': 300,\n",
    "    'lambda_l1': 35,\n",
    "    'lambda_l2': 65,\n",
    "    'min_gain_to_split': 7.394615335964813,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 0.3\n",
    "                } \n",
    "d_train=lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "#train the model \n",
    "# clf=lgb.train(lgb_params,d_train) #train the model on 100 epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aa8a8-d1fc-41b2-b5af-013c47717289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# clf.save_model('model_lgbm.txt')\n",
    "# clf.save_model(\"model_lgbm.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a81bf-ad43-4e1f-9521-6c42bb0e0f29",
   "metadata": {},
   "source": [
    "##### Make predictions for hidden data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "270ddaa9-b33e-4b9a-9235-57dc263852b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "clf = lgb.Booster(model_file='model_lgbm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "361475d9-2dfe-4997-a7e3-a8b9529b8eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction on the TEST set\n",
    "x_hidden_test = x_hidden_test.drop(columns=['column00'])\n",
    "y_pred_test=clf.predict(x_hidden_test)\n",
    "#rounding the values\n",
    "y_pred_test=y_pred_test.round(0)\n",
    "#converting to bool\n",
    "y_pred_test=y_pred_test.astype(bool)\n",
    "y_pred_test=y_pred_test.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48771b4b-1f05-472a-a7fb-7c05cf957917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "assert x_hidden_test.shape[0] == test_encoded_df.shape[0], 'Sth wrong with sizes'\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b60ea21-f7f8-48ee-8d45-08df0a6465cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in csv\n",
    "pd.DataFrame(y_pred_test).to_csv(\"test_predictions.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa951be6-11ae-4f20-a2a8-75a85226cf78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction on the VALIDATION set\n",
    "x_hidden_val = x_hidden_val.drop(columns=['column00'])\n",
    "y_pred_val=clf.predict(x_hidden_val)\n",
    "#converting to bool\n",
    "y_pred_val=y_pred_val.astype(bool)\n",
    "y_pred_val=y_pred_val.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55a819f6-aeba-4302-abc4-85fa5e7d02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "assert x_hidden_val.shape[0] == val_encoded_df.shape[0], 'Sth wrong with sizes'\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85ca5122-8d70-4af1-a227-2f5019498d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in csv\n",
    "pd.DataFrame(y_pred_val).to_csv(\"validation_predictions.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36ec28-2819-48de-9e63-c5c8a482c042",
   "metadata": {},
   "source": [
    "**SUBMISSION:**\n",
    "http://big-data-competitions.westeurope.cloudapp.azure.com:8080/competitions/imdb/submit\n",
    "\n",
    "* group14\n",
    "* cDHYysIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66f25b-16b2-455f-aadd-98be1c60aa44",
   "metadata": {},
   "source": [
    "### Get some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "148e8a5f-f73c-4bd4-96d2-42cef80f8f84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#roc_auc_score metric\u001b[39;00m\n\u001b[1;32m      3\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m----> 4\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score, accuracy_score\n",
    "#roc_auc_score metric\n",
    "y_pred=clf.predict(x_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7133f68-32c0-4b82-97e6-6ed798ebf404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
